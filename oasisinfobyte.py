# -*- coding: utf-8 -*-
"""OasisInfobyte.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ShMiHcXnzxN9XbSmZnALaks13_Z2Z0gV
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import sklearn
import numpy as np
import matplotlib.pyplot as plt
import joblib
from joblib import dump
import pickle
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV, KFold
from sklearn.metrics import r2_score
import seaborn as sns

!pip install -U scikit-learn==1.5.0
!pip install joblib --upgrade

data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Advertising.csv')

data

data = data.drop('Unnamed: 0', axis =1) #dropping unnecessary variables such a Unnamed: 0 as it does not contribute to the final result
data

data.info()

data.describe()

data = pd.DataFrame(data)

data.hist(bins=50, figsize=(20,15))
plt.show()

Y = data['Sales']

for i in data:
  plt.scatter(data['Sales'], data[i])
  plt.xlabel('Sales')
  plt.ylabel(i)
  plt.title(f'Scatter Plot of Sales vs {i}')
  plt.show()

corr_matrix = data.corr()

corr_matrix["Sales"].sort_values(ascending=False
)

X = data.drop("Sales",axis=1)

scaler = StandardScaler()

scaled = scaler.fit_transform(X)
data = pd.DataFrame(scaled, columns=data.columns.drop('Sales'))
X = data

X

joblib.dump(scaler, 'scaler.joblib')

Xtrain,Xtest,Ytrain,Ytest=train_test_split(X,Y,test_size=0.2,random_state=42)

rf=RandomForestRegressor()

rf= RandomForestRegressor(n_estimators=1000, random_state=42)

rf.fit(Xtrain, Ytrain)

rf_pred = rf.predict(Xtest)

rf_pred

mae = mean_absolute_error(rf_pred,Ytest)
print("Mean absolute error :" ,mae)

r2 = r2_score(rf_pred, Ytest)
print(f"R-squared: {r2}")

joblib.dump(rf, 'rf.joblib')

pip install streamlit

import pickle
import joblib
import streamlit as st
joblib.dump(rf, 'rf.pkl')

pickle.dump(rf,open('rf.pkl','wb'))

with open('rf.pkl', 'rb') as model_file:
    model = pickle.load(model_file)

def preprocess_input(input_data):
    scaled_input = scaler.transform(input_data)
    return scaled_input

# Function to make predictions
def predict(input_data):
    scaled_input = preprocess_input(input_data)
    prediction = model.predict(scaled_input)
    return prediction

# Streamlit app code
if __name__ == '__main__':
    st.title('Model Prediction App')

    # User input fields
    TV = st.number_input("TV", min_value=0)
    Radio = st.number_input("Radio", min_value=0)
    Newspaper = st.number_input("Newspaper", min_value=0)

    # Example input for demonstration
    input_data = np.array([[TV, Radio, Newspaper]])  # Assuming this is your input format

    # Handle prediction
    if st.button('Predict'):
        prediction = predict(input_data)
        st.write('Prediction:', prediction)

